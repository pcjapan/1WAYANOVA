<h1>General Information</h1>
<p>This test is a one-way ANOVA, to compare means for three or more separate groups being measured on the same variable. The test assumes you <u>do not</u> have a particular hypothesis about the relationship between your groups, so <code>post-hoc</code> tests to show any difference between groups are run, along with the omnibus F-test.</p>
<p>If you have specific hypotheses about the difference between the groups, it would be better to carry out the ANOVA using <code>planned contrasts</code>. See <a href="https://doi.org/10.1093/beheco/arn020">Ruxton & Beauchamp</a> (2008) for more details. Planned contrast functionality is not currently available with this application, but I hope to add it in the future.</p>
<p>A number of different test variations are available. Based on the tests of assumptions for your data, choose the option that is most appropriate. I would recommend using the robust alternative in all cases and reporting its outcomes; you could include this alongside a standard ANOVA for example. <a href="https://doi.org/10.1016/j.brat.2017.05.013">Field & Wilcox</a> (2017) provides a rationale for this approach.</p>
<h4>Data Input</h4>
<p>Prepare your data in a text file or spreadsheet with two columns: your <b>grouping</b> column, and an <b>outcome</b> column containing the actual response measures from your research groups. Prepare this in the same format as on the application front page, with 1 row per group by subject. Copy and paste your data into the <code>Grouping Variable</code> and <code>Response</code> text areas on the application page.</p>

<h4>Post-hoc Tests</h4>
<p>Post-hoc tests show you the association between each of your variables. Various options are provided for the post-hoc tests. There is a lot of debate about which test works best under which conditions. While the Bonferroni correction is often used, this is seen as being overly conservative. The default setting is to use the Holm adjustment. However, you should choose the option that is most appropriate for your data. <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust">Some details are given here</a>.</p>        

<h2>Procedure</h2>
<p>Once you have entered your data into the application text areas, follow these steps:</p>
<ol>
<li>Choose the type of test you want to perform,</li>
<li>Where appropriate, choose the post-hoc analysis you want to run,</li>
<li>Choose the robust test bootstrap and trimmed mean parameters.</li>
</ol>
<p>The <cite>Results Output</cite> displays the following:</p>
<ul>
<li>the ANOVA result</li>
<li>Multiple Tukey pairwise comparisons</li>
<li>Pairwise comparisons across group levels</li>
</ul>
<p>Under the <cite>Exploring Data</cite> tab, the application displays descriptive statistics and a a number of graphs.</p>
<ul>
<li>A shaprio-wilks test is also performed on the residuals of the ANOVA result. Here too, a value of normtest.p less than 0.05 (a statistically significant value) indicates the data is not normally distributed.</li>
<li>Also check the Q-Q plot of both the residuals and the groups. A normally distributed sample will have the points lying approximately along the diagonal line - deviation from this shows problems with the data set. The Q-Q plot gives a better indication of normality than the the Shapiro-Wilk test when sample sizes are large (greater than 50 is one figure I have seen) as the latter can give incorrect results with large samples.</li>
</ul>

<h4>References</h4>
<ul>
<li>Field, A. P., & Wilcox, R. R. (2017). Robust statistical methods: A primer for clinical psychology and experimental psychopathology researchers. <cite>Behaviour Research and Therapy, 98</cite>, 19–38. https://doi.org/10.1016/j.brat.2017.05.013</li>
<li>Ruxton, G. D., & Beauchamp, G. (2008). Time for some a priori thinking about post hoc testing. <cite>Behavioral Ecology 19</cite>(3), 690–693. https://doi.org/10.1093/beheco/arn020</li>
</ul>